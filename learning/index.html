<!doctype html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />

    <title>carl.learning API documentation</title>
    <meta name="description" content="This module implements machine learning algorithms and utilities,
complementary to Scikit-Learn." />

  <link href='http://fonts.googleapis.com/css?family=Source+Sans+Pro:400,300' rel='stylesheet' type='text/css'>
  
  <style type="text/css">
  
* {
  box-sizing: border-box;
}
/*! normalize.css v1.1.1 | MIT License | git.io/normalize */

/* ==========================================================================
   HTML5 display definitions
   ========================================================================== */

/**
 * Correct `block` display not defined in IE 6/7/8/9 and Firefox 3.
 */

article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
nav,
section,
summary {
    display: block;
}

/**
 * Correct `inline-block` display not defined in IE 6/7/8/9 and Firefox 3.
 */

audio,
canvas,
video {
    display: inline-block;
    *display: inline;
    *zoom: 1;
}

/**
 * Prevent modern browsers from displaying `audio` without controls.
 * Remove excess height in iOS 5 devices.
 */

audio:not([controls]) {
    display: none;
    height: 0;
}

/**
 * Address styling not present in IE 7/8/9, Firefox 3, and Safari 4.
 * Known issue: no IE 6 support.
 */

[hidden] {
    display: none;
}

/* ==========================================================================
   Base
   ========================================================================== */

/**
 * 1. Prevent system color scheme's background color being used in Firefox, IE,
 *    and Opera.
 * 2. Prevent system color scheme's text color being used in Firefox, IE, and
 *    Opera.
 * 3. Correct text resizing oddly in IE 6/7 when body `font-size` is set using
 *    `em` units.
 * 4. Prevent iOS text size adjust after orientation change, without disabling
 *    user zoom.
 */

html {
    background: #fff; /* 1 */
    color: #000; /* 2 */
    font-size: 100%; /* 3 */
    -webkit-text-size-adjust: 100%; /* 4 */
    -ms-text-size-adjust: 100%; /* 4 */
}

/**
 * Address `font-family` inconsistency between `textarea` and other form
 * elements.
 */

html,
button,
input,
select,
textarea {
    font-family: sans-serif;
}

/**
 * Address margins handled incorrectly in IE 6/7.
 */

body {
    margin: 0;
}

/* ==========================================================================
   Links
   ========================================================================== */

/**
 * Address `outline` inconsistency between Chrome and other browsers.
 */

a:focus {
    outline: thin dotted;
}

/**
 * Improve readability when focused and also mouse hovered in all browsers.
 */

a:active,
a:hover {
    outline: 0;
}

/* ==========================================================================
   Typography
   ========================================================================== */

/**
 * Address font sizes and margins set differently in IE 6/7.
 * Address font sizes within `section` and `article` in Firefox 4+, Safari 5,
 * and Chrome.
 */

h1 {
    font-size: 2em;
    margin: 0.67em 0;
}

h2 {
    font-size: 1.5em;
    margin: 0.83em 0;
}

h3 {
    font-size: 1.17em;
    margin: 1em 0;
}

h4 {
    font-size: 1em;
    margin: 1.33em 0;
}

h5 {
    font-size: 0.83em;
    margin: 1.67em 0;
}

h6 {
    font-size: 0.67em;
    margin: 2.33em 0;
}

/**
 * Address styling not present in IE 7/8/9, Safari 5, and Chrome.
 */

abbr[title] {
    border-bottom: 1px dotted;
}

/**
 * Address style set to `bolder` in Firefox 3+, Safari 4/5, and Chrome.
 */

b,
strong {
    font-weight: bold;
}

blockquote {
    margin: 1em 40px;
}

/**
 * Address styling not present in Safari 5 and Chrome.
 */

dfn {
    font-style: italic;
}

/**
 * Address differences between Firefox and other browsers.
 * Known issue: no IE 6/7 normalization.
 */

hr {
    -moz-box-sizing: content-box;
    box-sizing: content-box;
    height: 0;
}

/**
 * Address styling not present in IE 6/7/8/9.
 */

mark {
    background: #ff0;
    color: #000;
}

/**
 * Address margins set differently in IE 6/7.
 */

p,
pre {
    margin: 1em 0;
}

/**
 * Correct font family set oddly in IE 6, Safari 4/5, and Chrome.
 */

code,
kbd,
pre,
samp {
    font-family: monospace, serif;
    _font-family: 'courier new', monospace;
    font-size: 1em;
}

/**
 * Improve readability of pre-formatted text in all browsers.
 */

pre {
    white-space: pre;
    white-space: pre-wrap;
    word-wrap: break-word;
}

/**
 * Address CSS quotes not supported in IE 6/7.
 */

q {
    quotes: none;
}

/**
 * Address `quotes` property not supported in Safari 4.
 */

q:before,
q:after {
    content: '';
    content: none;
}

/**
 * Address inconsistent and variable font size in all browsers.
 */

small {
    font-size: 80%;
}

/**
 * Prevent `sub` and `sup` affecting `line-height` in all browsers.
 */

sub,
sup {
    font-size: 75%;
    line-height: 0;
    position: relative;
    vertical-align: baseline;
}

sup {
    top: -0.5em;
}

sub {
    bottom: -0.25em;
}

/* ==========================================================================
   Lists
   ========================================================================== */

/**
 * Address margins set differently in IE 6/7.
 */

dl,
menu,
ol,
ul {
    margin: 1em 0;
}

dd {
    margin: 0 0 0 40px;
}

/**
 * Address paddings set differently in IE 6/7.
 */

menu,
ol,
ul {
    padding: 0 0 0 40px;
}

/**
 * Correct list images handled incorrectly in IE 7.
 */

nav ul,
nav ol {
    list-style: none;
    list-style-image: none;
}

/* ==========================================================================
   Embedded content
   ========================================================================== */

/**
 * 1. Remove border when inside `a` element in IE 6/7/8/9 and Firefox 3.
 * 2. Improve image quality when scaled in IE 7.
 */

img {
    border: 0; /* 1 */
    -ms-interpolation-mode: bicubic; /* 2 */
}

/**
 * Correct overflow displayed oddly in IE 9.
 */

svg:not(:root) {
    overflow: hidden;
}

/* ==========================================================================
   Figures
   ========================================================================== */

/**
 * Address margin not present in IE 6/7/8/9, Safari 5, and Opera 11.
 */

figure {
    margin: 0;
}

/* ==========================================================================
   Forms
   ========================================================================== */

/**
 * Correct margin displayed oddly in IE 6/7.
 */

form {
    margin: 0;
}

/**
 * Define consistent border, margin, and padding.
 */

fieldset {
    border: 1px solid #c0c0c0;
    margin: 0 2px;
    padding: 0.35em 0.625em 0.75em;
}

/**
 * 1. Correct color not being inherited in IE 6/7/8/9.
 * 2. Correct text not wrapping in Firefox 3.
 * 3. Correct alignment displayed oddly in IE 6/7.
 */

legend {
    border: 0; /* 1 */
    padding: 0;
    white-space: normal; /* 2 */
    *margin-left: -7px; /* 3 */
}

/**
 * 1. Correct font size not being inherited in all browsers.
 * 2. Address margins set differently in IE 6/7, Firefox 3+, Safari 5,
 *    and Chrome.
 * 3. Improve appearance and consistency in all browsers.
 */

button,
input,
select,
textarea {
    font-size: 100%; /* 1 */
    margin: 0; /* 2 */
    vertical-align: baseline; /* 3 */
    *vertical-align: middle; /* 3 */
}

/**
 * Address Firefox 3+ setting `line-height` on `input` using `!important` in
 * the UA stylesheet.
 */

button,
input {
    line-height: normal;
}

/**
 * Address inconsistent `text-transform` inheritance for `button` and `select`.
 * All other form control elements do not inherit `text-transform` values.
 * Correct `button` style inheritance in Chrome, Safari 5+, and IE 6+.
 * Correct `select` style inheritance in Firefox 4+ and Opera.
 */

button,
select {
    text-transform: none;
}

/**
 * 1. Avoid the WebKit bug in Android 4.0.* where (2) destroys native `audio`
 *    and `video` controls.
 * 2. Correct inability to style clickable `input` types in iOS.
 * 3. Improve usability and consistency of cursor style between image-type
 *    `input` and others.
 * 4. Remove inner spacing in IE 7 without affecting normal text inputs.
 *    Known issue: inner spacing remains in IE 6.
 */

button,
html input[type="button"], /* 1 */
input[type="reset"],
input[type="submit"] {
    -webkit-appearance: button; /* 2 */
    cursor: pointer; /* 3 */
    *overflow: visible;  /* 4 */
}

/**
 * Re-set default cursor for disabled elements.
 */

button[disabled],
html input[disabled] {
    cursor: default;
}

/**
 * 1. Address box sizing set to content-box in IE 8/9.
 * 2. Remove excess padding in IE 8/9.
 * 3. Remove excess padding in IE 7.
 *    Known issue: excess padding remains in IE 6.
 */

input[type="checkbox"],
input[type="radio"] {
    box-sizing: border-box; /* 1 */
    padding: 0; /* 2 */
    *height: 13px; /* 3 */
    *width: 13px; /* 3 */
}

/**
 * 1. Address `appearance` set to `searchfield` in Safari 5 and Chrome.
 * 2. Address `box-sizing` set to `border-box` in Safari 5 and Chrome
 *    (include `-moz` to future-proof).
 */

input[type="search"] {
    -webkit-appearance: textfield; /* 1 */
    -moz-box-sizing: content-box;
    -webkit-box-sizing: content-box; /* 2 */
    box-sizing: content-box;
}

/**
 * Remove inner padding and search cancel button in Safari 5 and Chrome
 * on OS X.
 */

input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
    -webkit-appearance: none;
}

/**
 * Remove inner padding and border in Firefox 3+.
 */

button::-moz-focus-inner,
input::-moz-focus-inner {
    border: 0;
    padding: 0;
}

/**
 * 1. Remove default vertical scrollbar in IE 6/7/8/9.
 * 2. Improve readability and alignment in all browsers.
 */

textarea {
    overflow: auto; /* 1 */
    vertical-align: top; /* 2 */
}

/* ==========================================================================
   Tables
   ========================================================================== */

/**
 * Remove most spacing between table cells.
 */

table {
    border-collapse: collapse;
    border-spacing: 0;
}

  </style>

  <style type="text/css">
  
  html, body {
    margin: 0;
    padding: 0;
    min-height: 100%;
  }
  body {
    background: #fff;
    font-family: "Source Sans Pro", "Helvetica Neueue", Helvetica, sans;
    font-weight: 300;
    font-size: 16px;
    line-height: 1.6em;
  }
  #content {
    width: 70%;
    max-width: 850px;
    float: left;
    padding: 30px 60px;
    border-left: 1px solid #ddd;
  }
  #sidebar {
    width: 25%;
    float: left;
    padding: 30px;
    padding-top: 0px;
    overflow: hidden;
  }
  #nav {
    font-size: 130%;
    margin: 0 0 15px 0;
  }

  #top {
    display: block;
    position: fixed;
    bottom: 5px;
    left: 5px;
    font-size: .85em;
    text-transform: uppercase;
  }

  #footer {
    font-size: .75em;
    padding: 5px 30px;
    border-top: 1px solid #ddd;
    text-align: right;
  }
    #footer p {
      margin: 0 0 0 30px;
      display: inline-block;
    }

  h1, h2, h3, h4, h5 {
    font-weight: 300;
  }
  h1 {
    font-size: 2.5em;
    line-height: 1.1em;
    margin: 0 0 .50em 0;
  }

  h2 {
    font-size: 1.75em;
    margin: 1em 0 .50em 0;
  }

  h3 {
    margin: 25px 0 10px 0;
  }

  h4 {
    margin: 0;
    font-size: 105%;
  }

  a {
    color: #058;
    text-decoration: none;
    transition: color .3s ease-in-out;
  }

  a:hover {
    color: #e08524;
    transition: color .3s ease-in-out;
  }

  pre, code, .mono, .name {
    font-family: "Ubuntu Mono", "Cousine", "DejaVu Sans Mono", monospace;
  }

  .title .name {
    font-weight: bold;
  }
  .section-title {
    margin-top: 2em;
  }
  .ident {
    color: #900;
  }

  code {
    background: #f9f9f9;
  }

  pre {
    background: #fefefe;
    border: 1px solid #ddd;
    box-shadow: 2px 2px 0 #f3f3f3;
    margin: 0 30px;
    padding: 15px 30px;
  }

  .codehilite {
    margin: 0 30px 10px 30px;
  }

    .codehilite pre {
      margin: 0;
    }
    .codehilite .err { background: #ff3300; color: #fff !important; }

  table#module-list {
    font-size: 110%;
  }

    table#module-list tr td:first-child {
      padding-right: 10px;
      white-space: nowrap;
    }

    table#module-list td {
      vertical-align: top;
      padding-bottom: 8px;
    }

      table#module-list td p {
        margin: 0 0 7px 0;
      }

  .def {
    display: table;
  }

    .def p {
      display: table-cell;
      vertical-align: top;
      text-align: left;
    }

    .def p:first-child {
      white-space: nowrap;
    }

    .def p:last-child {
      width: 100%;
    }


  #index {
    list-style-type: none;
    margin: 0;
    padding: 0;
  }
    ul#index .class_name {
      /* font-size: 110%; */
      font-weight: bold;
    }
    #index ul {
      margin: 0;
    }

  .item {
    margin: 0 0 15px 0;
  }

    .item .class {
      margin: 0 0 25px 30px;
    }

      .item .class ul.class_list {
        margin: 0 0 20px 0;
      }

    .item .name {
      background: #fafafa;
      margin: 0;
      font-weight: bold;
      padding: 5px 10px;
      border-radius: 3px;
      display: inline-block;
      min-width: 40%;
    }
      .item .name:hover {
        background: #f6f6f6;
      }

    .item .empty_desc {
      margin: 0 0 5px 0;
      padding: 0;
    }

    .item .inheritance {
      margin: 3px 0 0 30px;
    }

    .item .inherited {
      color: #666;
    }

    .item .desc {
      padding: 0 8px;
      margin: 0;
    }

      .item .desc p {
        margin: 0 0 10px 0;
      }

    .source_cont {
      margin: 0;
      padding: 0;
    }

    .source_link a {
      background: #ffc300;
      font-weight: 400;
      font-size: .75em;
      text-transform: uppercase;
      color: #fff;
      text-shadow: 1px 1px 0 #f4b700;

      padding: 3px 8px;
      border-radius: 2px;
      transition: background .3s ease-in-out;
    }
      .source_link a:hover {
        background: #FF7200;
        text-shadow: none;
        transition: background .3s ease-in-out;
      }

    .source {
      display: none;
      max-height: 600px;
      overflow-y: scroll;
      margin-bottom: 15px;
    }

      .source .codehilite {
        margin: 0;
      }

  .desc h1, .desc h2, .desc h3 {
    font-size: 100% !important;
  }
  .clear {
    clear: both;
  }

  @media all and (max-width: 950px) {
    #sidebar {
      width: 35%;
    }
    #content {
      width: 65%;
    }
  }
  @media all and (max-width: 650px) {
    #top {
      display: none;
    }
    #sidebar {
      float: none;
      width: auto;
    }
    #content {
      float: none;
      width: auto;
      padding: 30px;
    }

    #index ul {
      padding: 0;
      margin-bottom: 15px;
    }
    #index ul li {
      display: inline-block;
      margin-right: 30px;
    }
    #footer {
      text-align: left;
    }
    #footer p {
      display: block;
      margin: inherit;
    }
  }

  /*****************************/

  </style>

  <style type="text/css">
  .codehilite .hll { background-color: #ffffcc }
.codehilite  { background: #f8f8f8; }
.codehilite .c { color: #408080; font-style: italic } /* Comment */
.codehilite .err { border: 1px solid #FF0000 } /* Error */
.codehilite .k { color: #008000; font-weight: bold } /* Keyword */
.codehilite .o { color: #666666 } /* Operator */
.codehilite .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.codehilite .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.codehilite .cp { color: #BC7A00 } /* Comment.Preproc */
.codehilite .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.codehilite .c1 { color: #408080; font-style: italic } /* Comment.Single */
.codehilite .cs { color: #408080; font-style: italic } /* Comment.Special */
.codehilite .gd { color: #A00000 } /* Generic.Deleted */
.codehilite .ge { font-style: italic } /* Generic.Emph */
.codehilite .gr { color: #FF0000 } /* Generic.Error */
.codehilite .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.codehilite .gi { color: #00A000 } /* Generic.Inserted */
.codehilite .go { color: #888888 } /* Generic.Output */
.codehilite .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.codehilite .gs { font-weight: bold } /* Generic.Strong */
.codehilite .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.codehilite .gt { color: #0044DD } /* Generic.Traceback */
.codehilite .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.codehilite .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.codehilite .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.codehilite .kp { color: #008000 } /* Keyword.Pseudo */
.codehilite .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.codehilite .kt { color: #B00040 } /* Keyword.Type */
.codehilite .m { color: #666666 } /* Literal.Number */
.codehilite .s { color: #BA2121 } /* Literal.String */
.codehilite .na { color: #7D9029 } /* Name.Attribute */
.codehilite .nb { color: #008000 } /* Name.Builtin */
.codehilite .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.codehilite .no { color: #880000 } /* Name.Constant */
.codehilite .nd { color: #AA22FF } /* Name.Decorator */
.codehilite .ni { color: #999999; font-weight: bold } /* Name.Entity */
.codehilite .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.codehilite .nf { color: #0000FF } /* Name.Function */
.codehilite .nl { color: #A0A000 } /* Name.Label */
.codehilite .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.codehilite .nt { color: #008000; font-weight: bold } /* Name.Tag */
.codehilite .nv { color: #19177C } /* Name.Variable */
.codehilite .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.codehilite .w { color: #bbbbbb } /* Text.Whitespace */
.codehilite .mb { color: #666666 } /* Literal.Number.Bin */
.codehilite .mf { color: #666666 } /* Literal.Number.Float */
.codehilite .mh { color: #666666 } /* Literal.Number.Hex */
.codehilite .mi { color: #666666 } /* Literal.Number.Integer */
.codehilite .mo { color: #666666 } /* Literal.Number.Oct */
.codehilite .sb { color: #BA2121 } /* Literal.String.Backtick */
.codehilite .sc { color: #BA2121 } /* Literal.String.Char */
.codehilite .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.codehilite .s2 { color: #BA2121 } /* Literal.String.Double */
.codehilite .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.codehilite .sh { color: #BA2121 } /* Literal.String.Heredoc */
.codehilite .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.codehilite .sx { color: #008000 } /* Literal.String.Other */
.codehilite .sr { color: #BB6688 } /* Literal.String.Regex */
.codehilite .s1 { color: #BA2121 } /* Literal.String.Single */
.codehilite .ss { color: #19177C } /* Literal.String.Symbol */
.codehilite .bp { color: #008000 } /* Name.Builtin.Pseudo */
.codehilite .vc { color: #19177C } /* Name.Variable.Class */
.codehilite .vg { color: #19177C } /* Name.Variable.Global */
.codehilite .vi { color: #19177C } /* Name.Variable.Instance */
.codehilite .il { color: #666666 } /* Literal.Number.Integer.Long */
  </style>

  <style type="text/css">
  
/* ==========================================================================
   EXAMPLE Media Queries for Responsive Design.
   These examples override the primary ('mobile first') styles.
   Modify as content requires.
   ========================================================================== */

@media only screen and (min-width: 35em) {
    /* Style adjustments for viewports that meet the condition */
}

@media print,
       (-o-min-device-pixel-ratio: 5/4),
       (-webkit-min-device-pixel-ratio: 1.25),
       (min-resolution: 120dpi) {
    /* Style adjustments for high resolution devices */
}

/* ==========================================================================
   Print styles.
   Inlined to avoid required HTTP connection: h5bp.com/r
   ========================================================================== */

@media print {
    * {
        background: transparent !important;
        color: #000 !important; /* Black prints faster: h5bp.com/s */
        box-shadow: none !important;
        text-shadow: none !important;
    }

    a,
    a:visited {
        text-decoration: underline;
    }

    a[href]:after {
        content: " (" attr(href) ")";
    }

    abbr[title]:after {
        content: " (" attr(title) ")";
    }

    /*
     * Don't show links for images, or javascript/internal links
     */

    .ir a:after,
    a[href^="javascript:"]:after,
    a[href^="#"]:after {
        content: "";
    }

    pre,
    blockquote {
        border: 1px solid #999;
        page-break-inside: avoid;
    }

    thead {
        display: table-header-group; /* h5bp.com/t */
    }

    tr,
    img {
        page-break-inside: avoid;
    }

    img {
        max-width: 100% !important;
    }

    @page {
        margin: 0.5cm;
    }

    p,
    h2,
    h3 {
        orphans: 3;
        widows: 3;
    }

    h2,
    h3 {
        page-break-after: avoid;
    }
}

  </style>

  <script type="text/javascript">
  function toggle(id, $link) {
    $node = document.getElementById(id);
    if (!$node)
    return;
    if (!$node.style.display || $node.style.display == 'none') {
    $node.style.display = 'block';
    $link.innerHTML = 'Hide source &nequiv;';
    } else {
    $node.style.display = 'none';
    $link.innerHTML = 'Show source &equiv;';
    }
  }
  </script>
  <script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
  </script>
</head>
<body>
<a href="https://github.com/diana-hep/carl"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://camo.githubusercontent.com/652c5b9acfaddf3a9c326fa6bde407b87f7be0f4/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f6f72616e67655f6666373630302e706e67" alt="Fork me on GitHub" data-canonical-src="https://s3.amazonaws.com/github/ribbons/forkme_right_orange_ff7600.png"></a>
<a href="#" id="top">Top</a>

<div id="container">
    
  
  <div id="sidebar">
    <ul id="index">

    <li class="set"><h3><a href="#header-functions">Functions</a></h3>
      
  <ul>
    <li class="mono"><a href="#carl.learning.as_classifier">as_classifier</a></li>
    <li class="mono"><a href="#carl.learning.check_cv">check_cv</a></li>
    <li class="mono"><a href="#carl.learning.make_parameterized_classification">make_parameterized_classification</a></li>
  </ul>

    </li>

    <li class="set"><h3><a href="#header-classes">Classes</a></h3>
      <ul>
        <li class="mono">
        <span class="class_name"><a href="#carl.learning.CalibratedClassifierCV">CalibratedClassifierCV</a></span>
        </li>
        <li class="mono">
        <span class="class_name"><a href="#carl.learning.ParameterStacker">ParameterStacker</a></span>
        </li>
        <li class="mono">
        <span class="class_name"><a href="#carl.learning.ParameterizedClassifier">ParameterizedClassifier</a></span>
        </li>
        <li class="mono">
        <span class="class_name"><a href="#carl.learning.ParameterizedRegressor">ParameterizedRegressor</a></span>
        </li>
      </ul>
    </li>


    <li class="set"><h3><a href="http://diana-hep.org/carl/"></a></h3>
    </li>


    <li class="set"><h3><a href="http://diana-hep.org/carl/">Index</a></h3></li>
    </ul>
  </div>

    <article id="content">
          
  

  


  <header id="section-intro">
  <h1 class="title"><span class="name">carl.learning</span> module</h1>
  <p>This module implements machine learning algorithms and utilities,
complementary to Scikit-Learn.</p>
  
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-carl.learning', this);">Show source &equiv;</a></p>
  <div id="source-carl.learning" class="source">
    <div class="codehilite"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">This module implements machine learning algorithms and utilities,</span>
<span class="sd">complementary to Scikit-Learn.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c1"># Carl is free software; you can redistribute it and/or modify it</span>
<span class="c1"># under the terms of the Revised BSD License; see LICENSE file for</span>
<span class="c1"># more details.</span>

<span class="kn">from</span> <span class="nn">.base</span> <span class="kn">import</span> <span class="n">as_classifier</span>
<span class="kn">from</span> <span class="nn">.base</span> <span class="kn">import</span> <span class="n">check_cv</span>
<span class="kn">from</span> <span class="nn">.calibration</span> <span class="kn">import</span> <span class="n">CalibratedClassifierCV</span>
<span class="kn">from</span> <span class="nn">.parameterize</span> <span class="kn">import</span> <span class="n">make_parameterized_classification</span>
<span class="kn">from</span> <span class="nn">.parameterize</span> <span class="kn">import</span> <span class="n">ParameterStacker</span>
<span class="kn">from</span> <span class="nn">.parameterize</span> <span class="kn">import</span> <span class="n">ParameterizedClassifier</span>
<span class="kn">from</span> <span class="nn">.parameterize</span> <span class="kn">import</span> <span class="n">ParameterizedRegressor</span>


<span class="n">__all__</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;as_classifier&quot;</span><span class="p">,</span>
           <span class="s2">&quot;check_cv&quot;</span><span class="p">,</span>
           <span class="s2">&quot;CalibratedClassifierCV&quot;</span><span class="p">,</span>
           <span class="s2">&quot;make_parameterized_classification&quot;</span><span class="p">,</span>
           <span class="s2">&quot;ParameterStacker&quot;</span><span class="p">,</span>
           <span class="s2">&quot;ParameterizedClassifier&quot;</span><span class="p">,</span>
           <span class="s2">&quot;ParameterizedRegressor&quot;</span><span class="p">,)</span>
</pre></div>

  </div>

  </header>



  <section id="section-items">

    <h2 class="section-title" id="header-functions">Functions</h2>
      
  <div class="item">
    <div class="name def" id="carl.learning.as_classifier">
    <p>def <span class="ident">as_classifier</span>(</p><p>regressor)</p>
    </div>
    

    
  
    <div class="desc"><p>Wrap a Scikit-Learn regressor into a binary classifier.</p>
<p>This function can be used to solve a binary classification problem as a
regression problem, where output labels {0,1} are treated as real values.
The wrapped regressor exhibits the classifier API, with the corresponding
<code>predict</code>, <code>predict_proba</code> and <code>score</code> methods.</p>
<h2>Parameters</h2>
<ul>
<li><code>regressor</code> [<code>RegressorMixin</code>]:
    The regressor object.</li>
</ul>
<h2>Returns</h2>
<ul>
<li><code>clf</code> [<code>ClassifierMixin</code>]:
    The wrapped regressor, but with a classifier API.</li>
</ul></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-carl.learning.as_classifier', this);">Show source &equiv;</a></p>
  <div id="source-carl.learning.as_classifier" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">as_classifier</span><span class="p">(</span><span class="n">regressor</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Wrap a Scikit-Learn regressor into a binary classifier.</span>

<span class="sd">    This function can be used to solve a binary classification problem as a</span>
<span class="sd">    regression problem, where output labels {0,1} are treated as real values.</span>
<span class="sd">    The wrapped regressor exhibits the classifier API, with the corresponding</span>
<span class="sd">    `predict`, `predict_proba` and `score` methods.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    * `regressor` [`RegressorMixin`]:</span>
<span class="sd">        The regressor object.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    * `clf` [`ClassifierMixin`]:</span>
<span class="sd">        The wrapped regressor, but with a classifier API.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">class</span> <span class="nc">Wrapper</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">ClassifierMixin</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">base_estimator</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">base_estimator</span> <span class="o">=</span> <span class="n">base_estimator</span>

        <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="c1"># Check inputs</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">check_X_y</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

            <span class="c1"># Convert y</span>
            <span class="n">label_encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">classes_</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span>

            <span class="c1"># Fit regressor</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">regressor_</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_estimator</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

            <span class="k">return</span> <span class="bp">self</span>

        <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">,</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">classes_</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">classes_</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

            <span class="n">df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressor_</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="n">df</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
            <span class="n">probas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="mi">2</span><span class="p">))</span>
            <span class="n">probas</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">-</span> <span class="n">df</span>
            <span class="n">probas</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span>

            <span class="k">return</span> <span class="n">probas</span>

        <span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressor_</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">Wrapper</span><span class="p">(</span><span class="n">regressor</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="carl.learning.check_cv">
    <p>def <span class="ident">check_cv</span>(</p><p>cv=3, X=None, y=None, classifier=False)</p>
    </div>
    

    
  
    <div class="desc"><p>Input checker utility for building a cross-validator.</p>
<h2>Parameters</h2>
<ul>
<li>
<p><code>cv</code> [integer, cross-validation generator or an iterable, default=<code>3</code>]:
    Determines the cross-validation splitting strategy.
    Possible inputs for cv are:</p>
<ul>
<li>integer, to specify the number of folds.</li>
<li>An object to be used as a cross-validation generator.</li>
<li>An iterable yielding train/test splits.</li>
</ul>
<p>For integer/None inputs, if classifier is True and <code>y</code> is either
binary or multiclass, <code>StratifiedKFold</code> used. In all other
cases, <code>KFold</code> is used.</p>
</li>
<li>
<p><code>y</code> [array-like, optional]:
    The target variable for supervised learning problems.</p>
</li>
<li>
<p><code>classifier</code> [boolean, default=<code>False</code>]:
    Whether the task is a classification task, in which case
    stratified <code>KFold</code> will be used.</p>
</li>
</ul>
<h2>Returns</h2>
<ul>
<li><code>checked_cv</code> [a cross-validator instance]:
    The return value is a cross-validator which generates the train/test
    splits via the <code>split</code> method.</li>
</ul>
<h2>Note</h2>
<p>This method is backported from scikit-learn 0.18.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-carl.learning.check_cv', this);">Show source &equiv;</a></p>
  <div id="source-carl.learning.check_cv" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">check_cv</span><span class="p">(</span><span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">classifier</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Input checker utility for building a cross-validator.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    * `cv` [integer, cross-validation generator or an iterable, default=`3`]:</span>
<span class="sd">        Determines the cross-validation splitting strategy.</span>
<span class="sd">        Possible inputs for cv are:</span>

<span class="sd">          - integer, to specify the number of folds.</span>
<span class="sd">          - An object to be used as a cross-validation generator.</span>
<span class="sd">          - An iterable yielding train/test splits.</span>

<span class="sd">        For integer/None inputs, if classifier is True and `y` is either</span>
<span class="sd">        binary or multiclass, `StratifiedKFold` used. In all other</span>
<span class="sd">        cases, `KFold` is used.</span>

<span class="sd">    * `y` [array-like, optional]:</span>
<span class="sd">        The target variable for supervised learning problems.</span>

<span class="sd">    * `classifier` [boolean, default=`False`]:</span>
<span class="sd">        Whether the task is a classification task, in which case</span>
<span class="sd">        stratified `KFold` will be used.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    * `checked_cv` [a cross-validator instance]:</span>
<span class="sd">        The return value is a cross-validator which generates the train/test</span>
<span class="sd">        splits via the `split` method.</span>

<span class="sd">    Note</span>
<span class="sd">    ----</span>
<span class="sd">    This method is backported from scikit-learn 0.18.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">int</span><span class="p">(</span><span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span><span class="p">[</span><span class="mi">2</span><span class="p">:</span><span class="mi">4</span><span class="p">])</span> <span class="o">&gt;=</span> <span class="mi">18</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">check_cv</span> <span class="k">as</span> <span class="n">sklearn_check_cv</span>
        <span class="k">return</span> <span class="n">sklearn_check_cv</span><span class="p">(</span><span class="n">cv</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">classifier</span><span class="o">=</span><span class="n">classifier</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">check_cv</span> <span class="k">as</span> <span class="n">sklearn_check_cv</span>
        <span class="k">return</span> <span class="n">_CVIterableWrapper</span><span class="p">(</span><span class="n">sklearn_check_cv</span><span class="p">(</span><span class="n">cv</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
                                                   <span class="n">classifier</span><span class="o">=</span><span class="n">classifier</span><span class="p">))</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="carl.learning.make_parameterized_classification">
    <p>def <span class="ident">make_parameterized_classification</span>(</p><p>p0, p1, n_samples, params, random_state=None)</p>
    </div>
    

    
  
    <div class="desc"><p>Generate parameterized classification data.</p>
<p>This function generates parameterized classification data, by enumerating
all possible combinations of provided parameter values and producing
samples in equal number from <code>p0</code> and <code>p1</code>.</p>
<h2>Parameters</h2>
<ul>
<li>
<p><code>p0</code> [<code>DistributionMixin</code>]:
    The distribution to draw samples from class 0.</p>
</li>
<li>
<p><code>p1</code> [<code>DistributionMixin</code>]:
    The distribution to draw samples from class 1.</p>
</li>
<li>
<p><code>n_samples</code> [integer]:
    The total number of samples to generate.</p>
</li>
<li>
<p><code>params</code> [list of pairs (theano shared variables, list of values) or
            list of theano shared variables]:
    The list of parameters and the corresponding values to generate
    samples for. If only a list of theano shared variables is given, then
    generate samples using the current parameter values.</p>
</li>
<li>
<p><code>random_state</code> [integer or RandomState object]:
    The random seed.</p>
</li>
</ul>
<h2>Returns</h2>
<ul>
<li>
<p><code>X</code> [array, shape=(n_samples, n_features+len(params))]:
    The generated training data, as sample features and concatenated
    parameter values.</p>
</li>
<li>
<p><code>y</code> [array, shape=(n_samples,)]:
    The labels.</p>
</li>
</ul></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-carl.learning.make_parameterized_classification', this);">Show source &equiv;</a></p>
  <div id="source-carl.learning.make_parameterized_classification" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">make_parameterized_classification</span><span class="p">(</span><span class="n">p0</span><span class="p">,</span> <span class="n">p1</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span>
                                      <span class="n">random_state</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Generate parameterized classification data.</span>

<span class="sd">    This function generates parameterized classification data, by enumerating</span>
<span class="sd">    all possible combinations of provided parameter values and producing</span>
<span class="sd">    samples in equal number from `p0` and `p1`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    * `p0` [`DistributionMixin`]:</span>
<span class="sd">        The distribution to draw samples from class 0.</span>

<span class="sd">    * `p1` [`DistributionMixin`]:</span>
<span class="sd">        The distribution to draw samples from class 1.</span>

<span class="sd">    * `n_samples` [integer]:</span>
<span class="sd">        The total number of samples to generate.</span>

<span class="sd">    * `params` [list of pairs (theano shared variables, list of values) or</span>
<span class="sd">                list of theano shared variables]:</span>
<span class="sd">        The list of parameters and the corresponding values to generate</span>
<span class="sd">        samples for. If only a list of theano shared variables is given, then</span>
<span class="sd">        generate samples using the current parameter values.</span>

<span class="sd">    * `random_state` [integer or RandomState object]:</span>
<span class="sd">        The random seed.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    * `X` [array, shape=(n_samples, n_features+len(params))]:</span>
<span class="sd">        The generated training data, as sample features and concatenated</span>
<span class="sd">        parameter values.</span>

<span class="sd">    * `y` [array, shape=(n_samples,)]:</span>
<span class="sd">        The labels.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="n">X0</span> <span class="o">=</span> <span class="n">p0</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">n_samples</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
        <span class="n">X1</span> <span class="o">=</span> <span class="n">p1</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">n_samples</span> <span class="o">-</span> <span class="p">(</span><span class="n">n_samples</span> <span class="o">//</span> <span class="mi">2</span><span class="p">),</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">ParameterStacker</span><span class="p">(</span><span class="n">params</span><span class="p">)</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">X0</span><span class="p">,</span> <span class="n">X1</span><span class="p">)))</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
        <span class="n">y</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">X0</span><span class="p">):]</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>

    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="n">combinations</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">product</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">values</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">values</span> <span class="ow">in</span> <span class="n">params</span><span class="p">]))</span>

        <span class="n">all_X</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">all_y</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">combinations</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">c</span><span class="p">):</span>
                <span class="n">params</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

            <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_parameterized_classification</span><span class="p">(</span>
                <span class="n">p0</span><span class="p">,</span> <span class="n">p1</span><span class="p">,</span>
                <span class="n">n_samples</span> <span class="o">//</span> <span class="nb">len</span><span class="p">(</span><span class="n">combinations</span><span class="p">),</span>
                <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">params</span><span class="p">],</span>
                <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>

            <span class="n">all_X</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="n">all_y</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">all_X</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">all_y</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span>
</pre></div>

  </div>
</div>

  </div>
  

    <h2 class="section-title" id="header-classes">Classes</h2>
      
      <div class="item">
      <p id="carl.learning.CalibratedClassifierCV" class="name">class <span class="ident">CalibratedClassifierCV</span></p>
      
  
    <div class="desc"><p>Probability calibration.</p>
<p>With this class, the <code>base_estimator</code> is fit on the train set of the
cross-validation generator and the test set is used for calibration. The
probabilities for each of the folds are then averaged for prediction.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-carl.learning.CalibratedClassifierCV', this);">Show source &equiv;</a></p>
  <div id="source-carl.learning.CalibratedClassifierCV" class="source">
    <div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">CalibratedClassifierCV</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">ClassifierMixin</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Probability calibration.</span>

<span class="sd">    With this class, the `base_estimator` is fit on the train set of the</span>
<span class="sd">    cross-validation generator and the test set is used for calibration. The</span>
<span class="sd">    probabilities for each of the folds are then averaged for prediction.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">base_estimator</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;histogram&quot;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Constructor.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        * `base_estimator` [`ClassifierMixin`]:</span>
<span class="sd">            The classifier whose output decision function needs to be</span>
<span class="sd">            calibrated to offer more accurate predict_proba outputs. If</span>
<span class="sd">            `cv=prefit`, the classifier must have been fit already on data.</span>

<span class="sd">        * `method` [string]:</span>
<span class="sd">            The method to use for calibration. Supported methods include</span>
<span class="sd">            `&quot;histogram&quot;`, `&quot;kde&quot;`, `&quot;isotonic&quot;`, `&quot;interpolated-isotonic&quot;` and</span>
<span class="sd">            `&quot;sigmoid&quot;`.</span>

<span class="sd">        * `cv` [integer, cross-validation generator, iterable or `&quot;prefit&quot;`]:</span>
<span class="sd">            Determines the cross-validation splitting strategy.</span>
<span class="sd">            Possible inputs for cv are:</span>

<span class="sd">            - integer, to specify the number of folds.</span>
<span class="sd">            - An object to be used as a cross-validation generator.</span>
<span class="sd">            - An iterable yielding train/test splits.</span>

<span class="sd">            If `&quot;prefit&quot;` is passed, it is assumed that base_estimator has been</span>
<span class="sd">            fitted already and all data is used for calibration. If `cv=1`,</span>
<span class="sd">            the training data is used for both training and calibration.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_estimator</span> <span class="o">=</span> <span class="n">base_estimator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">=</span> <span class="n">method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cv</span> <span class="o">=</span> <span class="n">cv</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Fit the calibrated model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        * `X` [array-like, shape=(n_samples, n_features)]:</span>
<span class="sd">            Training data.</span>

<span class="sd">        * `y` [array-like, shape=(n_samples,)]:</span>
<span class="sd">            Target values.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        * `self` [object]:</span>
<span class="sd">            `self`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Check inputs</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">check_X_y</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="c1"># Convert y</span>
        <span class="n">label_encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">classes_</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span>

        <span class="c1"># Calibrator</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;histogram&quot;</span><span class="p">:</span>
            <span class="n">base_calibrator</span> <span class="o">=</span> <span class="n">HistogramCalibrator</span><span class="p">()</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;kde&quot;</span><span class="p">:</span>
            <span class="n">base_calibrator</span> <span class="o">=</span> <span class="n">KernelDensityCalibrator</span><span class="p">()</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;isotonic&quot;</span><span class="p">:</span>
            <span class="n">base_calibrator</span> <span class="o">=</span> <span class="n">IsotonicCalibrator</span><span class="p">()</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;interpolated-isotonic&quot;</span><span class="p">:</span>
            <span class="n">base_calibrator</span> <span class="o">=</span> <span class="n">IsotonicCalibrator</span><span class="p">(</span><span class="n">interpolation</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;sigmoid&quot;</span><span class="p">:</span>
            <span class="n">base_calibrator</span> <span class="o">=</span> <span class="n">SigmoidCalibrator</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">base_calibrator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span>

        <span class="c1"># Fit</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cv</span> <span class="o">==</span> <span class="s2">&quot;prefit&quot;</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">cv</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># Classifier</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cv</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">clf</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_estimator</span><span class="p">)</span>

                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">RegressorMixin</span><span class="p">):</span>
                    <span class="n">clf</span> <span class="o">=</span> <span class="n">as_classifier</span><span class="p">(</span><span class="n">clf</span><span class="p">)</span>

                <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="n">clf</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_estimator</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">classifiers_</span> <span class="o">=</span> <span class="p">[</span><span class="n">clf</span><span class="p">]</span>

            <span class="c1"># Calibrator</span>
            <span class="n">calibrator</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="n">base_calibrator</span><span class="p">)</span>
            <span class="n">T</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">calibrator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">calibrators_</span> <span class="o">=</span> <span class="p">[</span><span class="n">calibrator</span><span class="p">]</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">classifiers_</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">calibrators_</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="n">cv</span> <span class="o">=</span> <span class="n">check_cv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cv</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">classifier</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">calibrate</span> <span class="ow">in</span> <span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
                <span class="c1"># Classifier</span>
                <span class="n">clf</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_estimator</span><span class="p">)</span>

                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">RegressorMixin</span><span class="p">):</span>
                    <span class="n">clf</span> <span class="o">=</span> <span class="n">as_classifier</span><span class="p">(</span><span class="n">clf</span><span class="p">)</span>

                <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">train</span><span class="p">])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">classifiers_</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">clf</span><span class="p">)</span>

                <span class="c1"># Calibrator</span>
                <span class="n">calibrator</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="n">base_calibrator</span><span class="p">)</span>
                <span class="n">T</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">calibrate</span><span class="p">])[:,</span> <span class="mi">1</span><span class="p">]</span>
                <span class="n">calibrator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">y</span><span class="p">[</span><span class="n">calibrate</span><span class="p">])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">calibrators_</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">calibrator</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Predict the targets for `X`.</span>

<span class="sd">        Can be different from the predictions of the uncalibrated classifier.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        * `X` [array-like, shape=(n_samples, n_features)]:</span>
<span class="sd">            The samples.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        * `y` [array, shape=(n_samples,)]:</span>
<span class="sd">            The predicted class.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">,</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">classes_</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">classes_</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Predict the posterior probabilities of classification for `X`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        * `X` [array-like, shape=(n_samples, n_features)]:</span>
<span class="sd">            The samples.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        * `probas` [array, shape=(n_samples, n_classes)]:</span>
<span class="sd">            The predicted probabilities.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="mi">2</span><span class="p">))</span>

        <span class="k">for</span> <span class="n">clf</span><span class="p">,</span> <span class="n">calibrator</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">classifiers_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">calibrators_</span><span class="p">):</span>
            <span class="n">p</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+=</span> <span class="n">calibrator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">])</span>

        <span class="n">p</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">classifiers_</span><span class="p">)</span>
        <span class="n">p</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">-</span> <span class="n">p</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">p</span>

    <span class="k">def</span> <span class="nf">_clone</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">estimator</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">original</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cv</span> <span class="o">==</span> <span class="s2">&quot;prefit&quot;</span><span class="p">:</span>
            <span class="n">estimator</span><span class="o">.</span><span class="n">base_estimator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_estimator</span>

        <span class="k">return</span> <span class="n">estimator</span>
</pre></div>

  </div>
</div>


      <div class="class">
          <h3>Ancestors (in MRO)</h3>
          <ul class="class_list">
          <li><a href="#carl.learning.CalibratedClassifierCV">CalibratedClassifierCV</a></li>
          <li>sklearn.base.BaseEstimator</li>
          <li>sklearn.base.ClassifierMixin</li>
          <li>builtins.object</li>
          </ul>
          <h3>Static methods</h3>
            
  <div class="item">
    <div class="name def" id="carl.learning.CalibratedClassifierCV.__init__">
    <p>def <span class="ident">__init__</span>(</p><p>self, base_estimator, method=&#39;histogram&#39;, cv=1)</p>
    </div>
    

    
  
    <div class="desc"><p>Constructor.</p>
<h2>Parameters</h2>
<ul>
<li>
<p><code>base_estimator</code> [<code>ClassifierMixin</code>]:
    The classifier whose output decision function needs to be
    calibrated to offer more accurate predict_proba outputs. If
    <code>cv=prefit</code>, the classifier must have been fit already on data.</p>
</li>
<li>
<p><code>method</code> [string]:
    The method to use for calibration. Supported methods include
    <code>"histogram"</code>, <code>"kde"</code>, <code>"isotonic"</code>, <code>"interpolated-isotonic"</code> and
    <code>"sigmoid"</code>.</p>
</li>
<li>
<p><code>cv</code> [integer, cross-validation generator, iterable or <code>"prefit"</code>]:
    Determines the cross-validation splitting strategy.
    Possible inputs for cv are:</p>
<ul>
<li>integer, to specify the number of folds.</li>
<li>An object to be used as a cross-validation generator.</li>
<li>An iterable yielding train/test splits.</li>
</ul>
<p>If <code>"prefit"</code> is passed, it is assumed that base_estimator has been
fitted already and all data is used for calibration. If <code>cv=1</code>,
the training data is used for both training and calibration.</p>
</li>
</ul></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-carl.learning.CalibratedClassifierCV.__init__', this);">Show source &equiv;</a></p>
  <div id="source-carl.learning.CalibratedClassifierCV.__init__" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">base_estimator</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;histogram&quot;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Constructor.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    * `base_estimator` [`ClassifierMixin`]:</span>
<span class="sd">        The classifier whose output decision function needs to be</span>
<span class="sd">        calibrated to offer more accurate predict_proba outputs. If</span>
<span class="sd">        `cv=prefit`, the classifier must have been fit already on data.</span>
<span class="sd">    * `method` [string]:</span>
<span class="sd">        The method to use for calibration. Supported methods include</span>
<span class="sd">        `&quot;histogram&quot;`, `&quot;kde&quot;`, `&quot;isotonic&quot;`, `&quot;interpolated-isotonic&quot;` and</span>
<span class="sd">        `&quot;sigmoid&quot;`.</span>
<span class="sd">    * `cv` [integer, cross-validation generator, iterable or `&quot;prefit&quot;`]:</span>
<span class="sd">        Determines the cross-validation splitting strategy.</span>
<span class="sd">        Possible inputs for cv are:</span>
<span class="sd">        - integer, to specify the number of folds.</span>
<span class="sd">        - An object to be used as a cross-validation generator.</span>
<span class="sd">        - An iterable yielding train/test splits.</span>
<span class="sd">        If `&quot;prefit&quot;` is passed, it is assumed that base_estimator has been</span>
<span class="sd">        fitted already and all data is used for calibration. If `cv=1`,</span>
<span class="sd">        the training data is used for both training and calibration.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">base_estimator</span> <span class="o">=</span> <span class="n">base_estimator</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">=</span> <span class="n">method</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">cv</span> <span class="o">=</span> <span class="n">cv</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="carl.learning.CalibratedClassifierCV.fit">
    <p>def <span class="ident">fit</span>(</p><p>self, X, y)</p>
    </div>
    

    
  
    <div class="desc"><p>Fit the calibrated model.</p>
<h2>Parameters</h2>
<ul>
<li>
<p><code>X</code> [array-like, shape=(n_samples, n_features)]:
    Training data.</p>
</li>
<li>
<p><code>y</code> [array-like, shape=(n_samples,)]:
    Target values.</p>
</li>
</ul>
<h2>Returns</h2>
<ul>
<li><code>self</code> [object]:
    <code>self</code>.</li>
</ul></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-carl.learning.CalibratedClassifierCV.fit', this);">Show source &equiv;</a></p>
  <div id="source-carl.learning.CalibratedClassifierCV.fit" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Fit the calibrated model.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    * `X` [array-like, shape=(n_samples, n_features)]:</span>
<span class="sd">        Training data.</span>
<span class="sd">    * `y` [array-like, shape=(n_samples,)]:</span>
<span class="sd">        Target values.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    * `self` [object]:</span>
<span class="sd">        `self`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Check inputs</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">check_X_y</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="c1"># Convert y</span>
    <span class="n">label_encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">classes_</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span>
    <span class="c1"># Calibrator</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;histogram&quot;</span><span class="p">:</span>
        <span class="n">base_calibrator</span> <span class="o">=</span> <span class="n">HistogramCalibrator</span><span class="p">()</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;kde&quot;</span><span class="p">:</span>
        <span class="n">base_calibrator</span> <span class="o">=</span> <span class="n">KernelDensityCalibrator</span><span class="p">()</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;isotonic&quot;</span><span class="p">:</span>
        <span class="n">base_calibrator</span> <span class="o">=</span> <span class="n">IsotonicCalibrator</span><span class="p">()</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;interpolated-isotonic&quot;</span><span class="p">:</span>
        <span class="n">base_calibrator</span> <span class="o">=</span> <span class="n">IsotonicCalibrator</span><span class="p">(</span><span class="n">interpolation</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;sigmoid&quot;</span><span class="p">:</span>
        <span class="n">base_calibrator</span> <span class="o">=</span> <span class="n">SigmoidCalibrator</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">base_calibrator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span>
    <span class="c1"># Fit</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cv</span> <span class="o">==</span> <span class="s2">&quot;prefit&quot;</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">cv</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># Classifier</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cv</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">clf</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_estimator</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">RegressorMixin</span><span class="p">):</span>
                <span class="n">clf</span> <span class="o">=</span> <span class="n">as_classifier</span><span class="p">(</span><span class="n">clf</span><span class="p">)</span>
            <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">clf</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_estimator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifiers_</span> <span class="o">=</span> <span class="p">[</span><span class="n">clf</span><span class="p">]</span>
        <span class="c1"># Calibrator</span>
        <span class="n">calibrator</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="n">base_calibrator</span><span class="p">)</span>
        <span class="n">T</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">calibrator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">calibrators_</span> <span class="o">=</span> <span class="p">[</span><span class="n">calibrator</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifiers_</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">calibrators_</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">cv</span> <span class="o">=</span> <span class="n">check_cv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cv</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">classifier</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">calibrate</span> <span class="ow">in</span> <span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
            <span class="c1"># Classifier</span>
            <span class="n">clf</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_estimator</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">RegressorMixin</span><span class="p">):</span>
                <span class="n">clf</span> <span class="o">=</span> <span class="n">as_classifier</span><span class="p">(</span><span class="n">clf</span><span class="p">)</span>
            <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">train</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">classifiers_</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">clf</span><span class="p">)</span>
            <span class="c1"># Calibrator</span>
            <span class="n">calibrator</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="n">base_calibrator</span><span class="p">)</span>
            <span class="n">T</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">calibrate</span><span class="p">])[:,</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">calibrator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">y</span><span class="p">[</span><span class="n">calibrate</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">calibrators_</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">calibrator</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="carl.learning.CalibratedClassifierCV.get_params">
    <p>def <span class="ident">get_params</span>(</p><p>self, deep=True)</p>
    </div>
    

    
  
    <div class="desc"><p>Get parameters for this estimator.</p>
<h2>Parameters</h2>
<p>deep: boolean, optional
    If True, will return the parameters for this estimator and
    contained subobjects that are estimators.</p>
<h2>Returns</h2>
<p>params : mapping of string to any
    Parameter names mapped to their values.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-carl.learning.CalibratedClassifierCV.get_params', this);">Show source &equiv;</a></p>
  <div id="source-carl.learning.CalibratedClassifierCV.get_params" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">get_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">deep</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get parameters for this estimator.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    deep: boolean, optional</span>
<span class="sd">        If True, will return the parameters for this estimator and</span>
<span class="sd">        contained subobjects that are estimators.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    params : mapping of string to any</span>
<span class="sd">        Parameter names mapped to their values.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">out</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_param_names</span><span class="p">():</span>
        <span class="c1"># We need deprecation warnings to always be on in order to</span>
        <span class="c1"># catch deprecated param values.</span>
        <span class="c1"># This is set in utils/__init__.py but it gets overwritten</span>
        <span class="c1"># when running under python3 somehow.</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;always&quot;</span><span class="p">,</span> <span class="ne">DeprecationWarning</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">(</span><span class="n">record</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">w</span><span class="p">:</span>
                <span class="n">value</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="ow">and</span> <span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">category</span> <span class="o">==</span> <span class="ne">DeprecationWarning</span><span class="p">:</span>
                <span class="c1"># if the parameter is deprecated, don&#39;t show it</span>
                <span class="k">continue</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">filters</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="c1"># XXX: should we rather test if instance of estimator?</span>
        <span class="k">if</span> <span class="n">deep</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="s1">&#39;get_params&#39;</span><span class="p">):</span>
            <span class="n">deep_items</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="n">out</span><span class="o">.</span><span class="n">update</span><span class="p">((</span><span class="n">key</span> <span class="o">+</span> <span class="s1">&#39;__&#39;</span> <span class="o">+</span> <span class="n">k</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">deep_items</span><span class="p">)</span>
        <span class="n">out</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
    <span class="k">return</span> <span class="n">out</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="carl.learning.CalibratedClassifierCV.predict">
    <p>def <span class="ident">predict</span>(</p><p>self, X)</p>
    </div>
    

    
  
    <div class="desc"><p>Predict the targets for <code>X</code>.</p>
<p>Can be different from the predictions of the uncalibrated classifier.</p>
<h2>Parameters</h2>
<ul>
<li><code>X</code> [array-like, shape=(n_samples, n_features)]:
    The samples.</li>
</ul>
<h2>Returns</h2>
<ul>
<li><code>y</code> [array, shape=(n_samples,)]:
    The predicted class.</li>
</ul></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-carl.learning.CalibratedClassifierCV.predict', this);">Show source &equiv;</a></p>
  <div id="source-carl.learning.CalibratedClassifierCV.predict" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Predict the targets for `X`.</span>
<span class="sd">    Can be different from the predictions of the uncalibrated classifier.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    * `X` [array-like, shape=(n_samples, n_features)]:</span>
<span class="sd">        The samples.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    * `y` [array, shape=(n_samples,)]:</span>
<span class="sd">        The predicted class.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">classes_</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">classes_</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="carl.learning.CalibratedClassifierCV.predict_proba">
    <p>def <span class="ident">predict_proba</span>(</p><p>self, X)</p>
    </div>
    

    
  
    <div class="desc"><p>Predict the posterior probabilities of classification for <code>X</code>.</p>
<h2>Parameters</h2>
<ul>
<li><code>X</code> [array-like, shape=(n_samples, n_features)]:
    The samples.</li>
</ul>
<h2>Returns</h2>
<ul>
<li><code>probas</code> [array, shape=(n_samples, n_classes)]:
    The predicted probabilities.</li>
</ul></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-carl.learning.CalibratedClassifierCV.predict_proba', this);">Show source &equiv;</a></p>
  <div id="source-carl.learning.CalibratedClassifierCV.predict_proba" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Predict the posterior probabilities of classification for `X`.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    * `X` [array-like, shape=(n_samples, n_features)]:</span>
<span class="sd">        The samples.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    * `probas` [array, shape=(n_samples, n_classes)]:</span>
<span class="sd">        The predicted probabilities.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="mi">2</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">clf</span><span class="p">,</span> <span class="n">calibrator</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">classifiers_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">calibrators_</span><span class="p">):</span>
        <span class="n">p</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+=</span> <span class="n">calibrator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">p</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">classifiers_</span><span class="p">)</span>
    <span class="n">p</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">-</span> <span class="n">p</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">p</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="carl.learning.CalibratedClassifierCV.score">
    <p>def <span class="ident">score</span>(</p><p>self, X, y, sample_weight=None)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<h2>Parameters</h2>
<p>X : array-like, shape = (n_samples, n_features)
    Test samples.</p>
<p>y : array-like, shape = (n_samples) or (n_samples, n_outputs)
    True labels for X.</p>
<p>sample_weight : array-like, shape = [n_samples], optional
    Sample weights.</p>
<h2>Returns</h2>
<p>score : float
    Mean accuracy of self.predict(X) wrt. y.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-carl.learning.CalibratedClassifierCV.score', this);">Show source &equiv;</a></p>
  <div id="source-carl.learning.CalibratedClassifierCV.score" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the mean accuracy on the given test data and labels.</span>
<span class="sd">    In multi-label classification, this is the subset accuracy</span>
<span class="sd">    which is a harsh metric since you require for each sample that</span>
<span class="sd">    each label set be correctly predicted.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : array-like, shape = (n_samples, n_features)</span>
<span class="sd">        Test samples.</span>
<span class="sd">    y : array-like, shape = (n_samples) or (n_samples, n_outputs)</span>
<span class="sd">        True labels for X.</span>
<span class="sd">    sample_weight : array-like, shape = [n_samples], optional</span>
<span class="sd">        Sample weights.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    score : float</span>
<span class="sd">        Mean accuracy of self.predict(X) wrt. y.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
    <span class="k">return</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="carl.learning.CalibratedClassifierCV.set_params">
    <p>def <span class="ident">set_params</span>(</p><p>self, **params)</p>
    </div>
    

    
  
    <div class="desc"><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The former have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2>Returns</h2>
<p>self</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-carl.learning.CalibratedClassifierCV.set_params', this);">Show source &equiv;</a></p>
  <div id="source-carl.learning.CalibratedClassifierCV.set_params" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">set_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Set the parameters of this estimator.</span>
<span class="sd">    The method works on simple estimators as well as on nested objects</span>
<span class="sd">    (such as pipelines). The former have parameters of the form</span>
<span class="sd">    ``&lt;component&gt;__&lt;parameter&gt;`` so that it&#39;s possible to update each</span>
<span class="sd">    component of a nested object.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    self</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">params</span><span class="p">:</span>
        <span class="c1"># Simple optimisation to gain speed (inspect is slow)</span>
        <span class="k">return</span> <span class="bp">self</span>
    <span class="n">valid_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_params</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">iteritems</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
        <span class="n">split</span> <span class="o">=</span> <span class="n">key</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;__&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">split</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># nested objects case</span>
            <span class="n">name</span><span class="p">,</span> <span class="n">sub_name</span> <span class="o">=</span> <span class="n">split</span>
            <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">valid_params</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Invalid parameter </span><span class="si">%s</span><span class="s1"> for estimator </span><span class="si">%s</span><span class="s1">. &#39;</span>
                                 <span class="s1">&#39;Check the list of available parameters &#39;</span>
                                 <span class="s1">&#39;with `estimator.get_params().keys()`.&#39;</span> <span class="o">%</span>
                                 <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="bp">self</span><span class="p">))</span>
            <span class="n">sub_object</span> <span class="o">=</span> <span class="n">valid_params</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
            <span class="n">sub_object</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="n">sub_name</span><span class="p">:</span> <span class="n">value</span><span class="p">})</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># simple objects case</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">valid_params</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Invalid parameter </span><span class="si">%s</span><span class="s1"> for estimator </span><span class="si">%s</span><span class="s1">. &#39;</span>
                                 <span class="s1">&#39;Check the list of available parameters &#39;</span>
                                 <span class="s1">&#39;with `estimator.get_params().keys()`.&#39;</span> <span class="o">%</span>
                                 <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="o">.</span><span class="n">__name__</span><span class="p">))</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span>
</pre></div>

  </div>
</div>

  </div>
  
          <h3>Instance variables</h3>
            <div class="item">
            <p id="carl.learning.CalibratedClassifierCV.base_estimator" class="name">var <span class="ident">base_estimator</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="carl.learning.CalibratedClassifierCV.cv" class="name">var <span class="ident">cv</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="carl.learning.CalibratedClassifierCV.method" class="name">var <span class="ident">method</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
      </div>
      </div>
      
      <div class="item">
      <p id="carl.learning.ParameterStacker" class="name">class <span class="ident">ParameterStacker</span></p>
      
  
    <div class="desc"><p>Stack current parameter values as additional features.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-carl.learning.ParameterStacker', this);">Show source &equiv;</a></p>
  <div id="source-carl.learning.ParameterStacker" class="source">
    <div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">ParameterStacker</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Stack current parameter values as additional features.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Constructor.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        * `params` [list of Theano shared variables]:</span>
<span class="sd">            The parameters.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">params</span>

    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Stack current parameter values as additional features.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        * `X` [array-like, shape=(n_samples, n_features)]:</span>
<span class="sd">            The samples.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        * `Xt` [array, shape=(n_samples, n_features+len(params))]:</span>
<span class="sd">            The horizontal concatenation of X with the current parameter</span>
<span class="sd">            values, added as new columns.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">Xp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">)))</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">):</span>
            <span class="n">Xp</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">Xp</span><span class="p">))</span>
</pre></div>

  </div>
</div>


      <div class="class">
          <h3>Ancestors (in MRO)</h3>
          <ul class="class_list">
          <li><a href="#carl.learning.ParameterStacker">ParameterStacker</a></li>
          <li>sklearn.base.BaseEstimator</li>
          <li>sklearn.base.TransformerMixin</li>
          <li>builtins.object</li>
          </ul>
          <h3>Static methods</h3>
            
  <div class="item">
    <div class="name def" id="carl.learning.ParameterStacker.__init__">
    <p>def <span class="ident">__init__</span>(</p><p>self, params)</p>
    </div>
    

    
  
    <div class="desc"><p>Constructor.</p>
<h2>Parameters</h2>
<ul>
<li><code>params</code> [list of Theano shared variables]:
    The parameters.</li>
</ul></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-carl.learning.ParameterStacker.__init__', this);">Show source &equiv;</a></p>
  <div id="source-carl.learning.ParameterStacker.__init__" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Constructor.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    * `params` [list of Theano shared variables]:</span>
<span class="sd">        The parameters.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">params</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="carl.learning.ParameterStacker.fit_transform">
    <p>def <span class="ident">fit_transform</span>(</p><p>self, X, y=None, **fit_params)</p>
    </div>
    

    
  
    <div class="desc"><p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<h2>Parameters</h2>
<p>X : numpy array of shape [n_samples, n_features]
    Training set.</p>
<p>y : numpy array of shape [n_samples]
    Target values.</p>
<h2>Returns</h2>
<p>X_new : numpy array of shape [n_samples, n_features_new]
    Transformed array.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-carl.learning.ParameterStacker.fit_transform', this);">Show source &equiv;</a></p>
  <div id="source-carl.learning.ParameterStacker.fit_transform" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">fit_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">fit_params</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Fit to data, then transform it.</span>
<span class="sd">    Fits transformer to X and y with optional parameters fit_params</span>
<span class="sd">    and returns a transformed version of X.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : numpy array of shape [n_samples, n_features]</span>
<span class="sd">        Training set.</span>
<span class="sd">    y : numpy array of shape [n_samples]</span>
<span class="sd">        Target values.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    X_new : numpy array of shape [n_samples, n_features_new]</span>
<span class="sd">        Transformed array.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># non-optimized default implementation; override when a better</span>
    <span class="c1"># method is possible for a given clustering algorithm</span>
    <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="c1"># fit method of arity 1 (unsupervised transformation)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">**</span><span class="n">fit_params</span><span class="p">)</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># fit method of arity 2 (supervised transformation)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">**</span><span class="n">fit_params</span><span class="p">)</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="carl.learning.ParameterStacker.get_params">
    <p>def <span class="ident">get_params</span>(</p><p>self, deep=True)</p>
    </div>
    

    
  
    <div class="desc"><p>Get parameters for this estimator.</p>
<h2>Parameters</h2>
<p>deep: boolean, optional
    If True, will return the parameters for this estimator and
    contained subobjects that are estimators.</p>
<h2>Returns</h2>
<p>params : mapping of string to any
    Parameter names mapped to their values.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-carl.learning.ParameterStacker.get_params', this);">Show source &equiv;</a></p>
  <div id="source-carl.learning.ParameterStacker.get_params" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">get_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">deep</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get parameters for this estimator.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    deep: boolean, optional</span>
<span class="sd">        If True, will return the parameters for this estimator and</span>
<span class="sd">        contained subobjects that are estimators.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    params : mapping of string to any</span>
<span class="sd">        Parameter names mapped to their values.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">out</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_param_names</span><span class="p">():</span>
        <span class="c1"># We need deprecation warnings to always be on in order to</span>
        <span class="c1"># catch deprecated param values.</span>
        <span class="c1"># This is set in utils/__init__.py but it gets overwritten</span>
        <span class="c1"># when running under python3 somehow.</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;always&quot;</span><span class="p">,</span> <span class="ne">DeprecationWarning</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">(</span><span class="n">record</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">w</span><span class="p">:</span>
                <span class="n">value</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="ow">and</span> <span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">category</span> <span class="o">==</span> <span class="ne">DeprecationWarning</span><span class="p">:</span>
                <span class="c1"># if the parameter is deprecated, don&#39;t show it</span>
                <span class="k">continue</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">filters</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="c1"># XXX: should we rather test if instance of estimator?</span>
        <span class="k">if</span> <span class="n">deep</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="s1">&#39;get_params&#39;</span><span class="p">):</span>
            <span class="n">deep_items</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="n">out</span><span class="o">.</span><span class="n">update</span><span class="p">((</span><span class="n">key</span> <span class="o">+</span> <span class="s1">&#39;__&#39;</span> <span class="o">+</span> <span class="n">k</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">deep_items</span><span class="p">)</span>
        <span class="n">out</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
    <span class="k">return</span> <span class="n">out</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="carl.learning.ParameterStacker.set_params">
    <p>def <span class="ident">set_params</span>(</p><p>self, **params)</p>
    </div>
    

    
  
    <div class="desc"><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The former have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2>Returns</h2>
<p>self</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-carl.learning.ParameterStacker.set_params', this);">Show source &equiv;</a></p>
  <div id="source-carl.learning.ParameterStacker.set_params" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">set_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Set the parameters of this estimator.</span>
<span class="sd">    The method works on simple estimators as well as on nested objects</span>
<span class="sd">    (such as pipelines). The former have parameters of the form</span>
<span class="sd">    ``&lt;component&gt;__&lt;parameter&gt;`` so that it&#39;s possible to update each</span>
<span class="sd">    component of a nested object.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    self</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">params</span><span class="p">:</span>
        <span class="c1"># Simple optimisation to gain speed (inspect is slow)</span>
        <span class="k">return</span> <span class="bp">self</span>
    <span class="n">valid_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_params</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">iteritems</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
        <span class="n">split</span> <span class="o">=</span> <span class="n">key</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;__&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">split</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># nested objects case</span>
            <span class="n">name</span><span class="p">,</span> <span class="n">sub_name</span> <span class="o">=</span> <span class="n">split</span>
            <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">valid_params</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Invalid parameter </span><span class="si">%s</span><span class="s1"> for estimator </span><span class="si">%s</span><span class="s1">. &#39;</span>
                                 <span class="s1">&#39;Check the list of available parameters &#39;</span>
                                 <span class="s1">&#39;with `estimator.get_params().keys()`.&#39;</span> <span class="o">%</span>
                                 <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="bp">self</span><span class="p">))</span>
            <span class="n">sub_object</span> <span class="o">=</span> <span class="n">valid_params</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
            <span class="n">sub_object</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="n">sub_name</span><span class="p">:</span> <span class="n">value</span><span class="p">})</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># simple objects case</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">valid_params</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Invalid parameter </span><span class="si">%s</span><span class="s1"> for estimator </span><span class="si">%s</span><span class="s1">. &#39;</span>
                                 <span class="s1">&#39;Check the list of available parameters &#39;</span>
                                 <span class="s1">&#39;with `estimator.get_params().keys()`.&#39;</span> <span class="o">%</span>
                                 <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="o">.</span><span class="n">__name__</span><span class="p">))</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="carl.learning.ParameterStacker.transform">
    <p>def <span class="ident">transform</span>(</p><p>self, X, y=None)</p>
    </div>
    

    
  
    <div class="desc"><p>Stack current parameter values as additional features.</p>
<h2>Parameters</h2>
<ul>
<li><code>X</code> [array-like, shape=(n_samples, n_features)]:
    The samples.</li>
</ul>
<h2>Returns</h2>
<ul>
<li><code>Xt</code> [array, shape=(n_samples, n_features+len(params))]:
    The horizontal concatenation of X with the current parameter
    values, added as new columns.</li>
</ul></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-carl.learning.ParameterStacker.transform', this);">Show source &equiv;</a></p>
  <div id="source-carl.learning.ParameterStacker.transform" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Stack current parameter values as additional features.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    * `X` [array-like, shape=(n_samples, n_features)]:</span>
<span class="sd">        The samples.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    * `Xt` [array, shape=(n_samples, n_features+len(params))]:</span>
<span class="sd">        The horizontal concatenation of X with the current parameter</span>
<span class="sd">        values, added as new columns.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">Xp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">)))</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">):</span>
        <span class="n">Xp</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">Xp</span><span class="p">))</span>
</pre></div>

  </div>
</div>

  </div>
  
          <h3>Instance variables</h3>
            <div class="item">
            <p id="carl.learning.ParameterStacker.params" class="name">var <span class="ident">params</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
      </div>
      </div>
      
      <div class="item">
      <p id="carl.learning.ParameterizedClassifier" class="name">class <span class="ident">ParameterizedClassifier</span></p>
      
  
    <div class="desc"><p>Parameterize a Scikit-Learn classifier.</p>
<p>This wrapper can be used to learn a parameterized classification problem,
where parameter values are automatically added as additional features.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-carl.learning.ParameterizedClassifier', this);">Show source &equiv;</a></p>
  <div id="source-carl.learning.ParameterizedClassifier" class="source">
    <div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">ParameterizedClassifier</span><span class="p">(</span><span class="n">_ParameterizedEstimator</span><span class="p">,</span> <span class="n">ClassifierMixin</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Parameterize a Scikit-Learn classifier.</span>

<span class="sd">    This wrapper can be used to learn a parameterized classification problem,</span>
<span class="sd">    where parameter values are automatically added as additional features.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Predict the posterior probabilities of classification for X.</span>

<span class="sd">        Parameter values are automatically appended from the current state</span>
<span class="sd">        of the parameters if those are not provided with X.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        * `X` [array-like, shape=(n_samples, n_features) or</span>
<span class="sd">                           shape=(n_samples, n_features+len(params))]:</span>
<span class="sd">            The samples.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        * `probas` [array, shape=(n_samples, n_classes)]:</span>
<span class="sd">            The predicted probabilities.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator_</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_validate_X</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
</pre></div>

  </div>
</div>


      <div class="class">
          <h3>Ancestors (in MRO)</h3>
          <ul class="class_list">
          <li><a href="#carl.learning.ParameterizedClassifier">ParameterizedClassifier</a></li>
          <li>carl.learning.parameterize._ParameterizedEstimator</li>
          <li>sklearn.base.BaseEstimator</li>
          <li>sklearn.base.ClassifierMixin</li>
          <li>builtins.object</li>
          </ul>
          <h3>Static methods</h3>
            
  <div class="item">
    <div class="name def" id="carl.learning.ParameterizedClassifier.__init__">
    <p>def <span class="ident">__init__</span>(</p><p>self, base_estimator, params)</p>
    </div>
    

    
  
    <div class="desc"><p>Constructor.</p>
<h2>Parameters</h2>
<ul>
<li>
<p><code>base_estimator</code> [<code>BaseEstimator</code>]:
    The estimator to parameterize.</p>
</li>
<li>
<p><code>params</code> [list of Theano shared variables]:
    The parameters.</p>
</li>
</ul></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-carl.learning.ParameterizedClassifier.__init__', this);">Show source &equiv;</a></p>
  <div id="source-carl.learning.ParameterizedClassifier.__init__" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">base_estimator</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Constructor.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    * `base_estimator` [`BaseEstimator`]:</span>
<span class="sd">        The estimator to parameterize.</span>
<span class="sd">    * `params` [list of Theano shared variables]:</span>
<span class="sd">        The parameters.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">base_estimator</span> <span class="o">=</span> <span class="n">base_estimator</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">params</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="carl.learning.ParameterizedClassifier.fit">
    <p>def <span class="ident">fit</span>(</p><p>self, X, y)</p>
    </div>
    

    
  
    <div class="desc"><p>Fit estimator on parameterized data.</p>
<h2>Parameters</h2>
<ul>
<li>
<p><code>X</code> [array-like, shape=(n_samples, n_features+len(params))]:
    The samples, concatenated with the corresponding parameter values.</p>
</li>
<li>
<p><code>y</code> [array-like, shape=(n_samples,)]:
    The output values.</p>
</li>
</ul>
<h2>Returns</h2>
<ul>
<li><code>self</code> [object]:
    <code>self</code>.</li>
</ul></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-carl.learning.ParameterizedClassifier.fit', this);">Show source &equiv;</a></p>
  <div id="source-carl.learning.ParameterizedClassifier.fit" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Fit estimator on parameterized data.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    * `X` [array-like, shape=(n_samples, n_features+len(params))]:</span>
<span class="sd">        The samples, concatenated with the corresponding parameter values.</span>
<span class="sd">    * `y` [array-like, shape=(n_samples,)]:</span>
<span class="sd">        The output values.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    * `self` [object]:</span>
<span class="sd">        `self`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">stacker_</span> <span class="o">=</span> <span class="n">ParameterStacker</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
    <span class="c1"># XXX: this assumes that X is extended with parameters</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_features_</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">estimator_</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_estimator</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="carl.learning.ParameterizedClassifier.get_params">
    <p>def <span class="ident">get_params</span>(</p><p>self, deep=True)</p>
    </div>
    

    
  
    <div class="desc"><p>Get parameters for this estimator.</p>
<h2>Parameters</h2>
<p>deep: boolean, optional
    If True, will return the parameters for this estimator and
    contained subobjects that are estimators.</p>
<h2>Returns</h2>
<p>params : mapping of string to any
    Parameter names mapped to their values.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-carl.learning.ParameterizedClassifier.get_params', this);">Show source &equiv;</a></p>
  <div id="source-carl.learning.ParameterizedClassifier.get_params" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">get_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">deep</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get parameters for this estimator.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    deep: boolean, optional</span>
<span class="sd">        If True, will return the parameters for this estimator and</span>
<span class="sd">        contained subobjects that are estimators.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    params : mapping of string to any</span>
<span class="sd">        Parameter names mapped to their values.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">out</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_param_names</span><span class="p">():</span>
        <span class="c1"># We need deprecation warnings to always be on in order to</span>
        <span class="c1"># catch deprecated param values.</span>
        <span class="c1"># This is set in utils/__init__.py but it gets overwritten</span>
        <span class="c1"># when running under python3 somehow.</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;always&quot;</span><span class="p">,</span> <span class="ne">DeprecationWarning</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">(</span><span class="n">record</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">w</span><span class="p">:</span>
                <span class="n">value</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="ow">and</span> <span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">category</span> <span class="o">==</span> <span class="ne">DeprecationWarning</span><span class="p">:</span>
                <span class="c1"># if the parameter is deprecated, don&#39;t show it</span>
                <span class="k">continue</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">filters</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="c1"># XXX: should we rather test if instance of estimator?</span>
        <span class="k">if</span> <span class="n">deep</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="s1">&#39;get_params&#39;</span><span class="p">):</span>
            <span class="n">deep_items</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="n">out</span><span class="o">.</span><span class="n">update</span><span class="p">((</span><span class="n">key</span> <span class="o">+</span> <span class="s1">&#39;__&#39;</span> <span class="o">+</span> <span class="n">k</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">deep_items</span><span class="p">)</span>
        <span class="n">out</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
    <span class="k">return</span> <span class="n">out</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="carl.learning.ParameterizedClassifier.predict">
    <p>def <span class="ident">predict</span>(</p><p>self, X)</p>
    </div>
    

    
  
    <div class="desc"><p>Predict the targets for <code>X</code>.</p>
<p>Parameter values are automatically appended from the current state
of the parameters if those are not provided with <code>X</code>.</p>
<h2>Parameters</h2>
<ul>
<li><code>X</code> [array-like, shape=(n_samples, n_features) or
                   shape=(n_samples, n_features+len(params))]:
    The samples.</li>
</ul>
<h2>Returns</h2>
<ul>
<li><code>y</code> [array, shape=(n_samples,)]:
    The predicted output values.</li>
</ul></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-carl.learning.ParameterizedClassifier.predict', this);">Show source &equiv;</a></p>
  <div id="source-carl.learning.ParameterizedClassifier.predict" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Predict the targets for `X`.</span>
<span class="sd">    Parameter values are automatically appended from the current state</span>
<span class="sd">    of the parameters if those are not provided with `X`.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    * `X` [array-like, shape=(n_samples, n_features) or</span>
<span class="sd">                       shape=(n_samples, n_features+len(params))]:</span>
<span class="sd">        The samples.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    * `y` [array, shape=(n_samples,)]:</span>
<span class="sd">        The predicted output values.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator_</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_validate_X</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="carl.learning.ParameterizedClassifier.predict_proba">
    <p>def <span class="ident">predict_proba</span>(</p><p>self, X)</p>
    </div>
    

    
  
    <div class="desc"><p>Predict the posterior probabilities of classification for X.</p>
<p>Parameter values are automatically appended from the current state
of the parameters if those are not provided with X.</p>
<h2>Parameters</h2>
<ul>
<li><code>X</code> [array-like, shape=(n_samples, n_features) or
                   shape=(n_samples, n_features+len(params))]:
    The samples.</li>
</ul>
<h2>Returns</h2>
<ul>
<li><code>probas</code> [array, shape=(n_samples, n_classes)]:
    The predicted probabilities.</li>
</ul></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-carl.learning.ParameterizedClassifier.predict_proba', this);">Show source &equiv;</a></p>
  <div id="source-carl.learning.ParameterizedClassifier.predict_proba" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Predict the posterior probabilities of classification for X.</span>
<span class="sd">    Parameter values are automatically appended from the current state</span>
<span class="sd">    of the parameters if those are not provided with X.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    * `X` [array-like, shape=(n_samples, n_features) or</span>
<span class="sd">                       shape=(n_samples, n_features+len(params))]:</span>
<span class="sd">        The samples.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    * `probas` [array, shape=(n_samples, n_classes)]:</span>
<span class="sd">        The predicted probabilities.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator_</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_validate_X</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="carl.learning.ParameterizedClassifier.score">
    <p>def <span class="ident">score</span>(</p><p>self, X, y, sample_weight=None)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<h2>Parameters</h2>
<p>X : array-like, shape = (n_samples, n_features)
    Test samples.</p>
<p>y : array-like, shape = (n_samples) or (n_samples, n_outputs)
    True labels for X.</p>
<p>sample_weight : array-like, shape = [n_samples], optional
    Sample weights.</p>
<h2>Returns</h2>
<p>score : float
    Mean accuracy of self.predict(X) wrt. y.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-carl.learning.ParameterizedClassifier.score', this);">Show source &equiv;</a></p>
  <div id="source-carl.learning.ParameterizedClassifier.score" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the mean accuracy on the given test data and labels.</span>
<span class="sd">    In multi-label classification, this is the subset accuracy</span>
<span class="sd">    which is a harsh metric since you require for each sample that</span>
<span class="sd">    each label set be correctly predicted.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : array-like, shape = (n_samples, n_features)</span>
<span class="sd">        Test samples.</span>
<span class="sd">    y : array-like, shape = (n_samples) or (n_samples, n_outputs)</span>
<span class="sd">        True labels for X.</span>
<span class="sd">    sample_weight : array-like, shape = [n_samples], optional</span>
<span class="sd">        Sample weights.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    score : float</span>
<span class="sd">        Mean accuracy of self.predict(X) wrt. y.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
    <span class="k">return</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="carl.learning.ParameterizedClassifier.set_params">
    <p>def <span class="ident">set_params</span>(</p><p>self, **params)</p>
    </div>
    

    
  
    <div class="desc"><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The former have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2>Returns</h2>
<p>self</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-carl.learning.ParameterizedClassifier.set_params', this);">Show source &equiv;</a></p>
  <div id="source-carl.learning.ParameterizedClassifier.set_params" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">set_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Set the parameters of this estimator.</span>
<span class="sd">    The method works on simple estimators as well as on nested objects</span>
<span class="sd">    (such as pipelines). The former have parameters of the form</span>
<span class="sd">    ``&lt;component&gt;__&lt;parameter&gt;`` so that it&#39;s possible to update each</span>
<span class="sd">    component of a nested object.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    self</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">params</span><span class="p">:</span>
        <span class="c1"># Simple optimisation to gain speed (inspect is slow)</span>
        <span class="k">return</span> <span class="bp">self</span>
    <span class="n">valid_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_params</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">iteritems</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
        <span class="n">split</span> <span class="o">=</span> <span class="n">key</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;__&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">split</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># nested objects case</span>
            <span class="n">name</span><span class="p">,</span> <span class="n">sub_name</span> <span class="o">=</span> <span class="n">split</span>
            <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">valid_params</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Invalid parameter </span><span class="si">%s</span><span class="s1"> for estimator </span><span class="si">%s</span><span class="s1">. &#39;</span>
                                 <span class="s1">&#39;Check the list of available parameters &#39;</span>
                                 <span class="s1">&#39;with `estimator.get_params().keys()`.&#39;</span> <span class="o">%</span>
                                 <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="bp">self</span><span class="p">))</span>
            <span class="n">sub_object</span> <span class="o">=</span> <span class="n">valid_params</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
            <span class="n">sub_object</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="n">sub_name</span><span class="p">:</span> <span class="n">value</span><span class="p">})</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># simple objects case</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">valid_params</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Invalid parameter </span><span class="si">%s</span><span class="s1"> for estimator </span><span class="si">%s</span><span class="s1">. &#39;</span>
                                 <span class="s1">&#39;Check the list of available parameters &#39;</span>
                                 <span class="s1">&#39;with `estimator.get_params().keys()`.&#39;</span> <span class="o">%</span>
                                 <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="o">.</span><span class="n">__name__</span><span class="p">))</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span>
</pre></div>

  </div>
</div>

  </div>
  
      </div>
      </div>
      
      <div class="item">
      <p id="carl.learning.ParameterizedRegressor" class="name">class <span class="ident">ParameterizedRegressor</span></p>
      
  
    <div class="desc"><p>Parameterize a Scikit-Learn regressor.</p>
<p>This wrapper can be used to learn a parameterized regression problem,
where parameter values are automatically added as additional features.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-carl.learning.ParameterizedRegressor', this);">Show source &equiv;</a></p>
  <div id="source-carl.learning.ParameterizedRegressor" class="source">
    <div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">ParameterizedRegressor</span><span class="p">(</span><span class="n">_ParameterizedEstimator</span><span class="p">,</span> <span class="n">RegressorMixin</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Parameterize a Scikit-Learn regressor.</span>

<span class="sd">    This wrapper can be used to learn a parameterized regression problem,</span>
<span class="sd">    where parameter values are automatically added as additional features.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">pass</span>
</pre></div>

  </div>
</div>


      <div class="class">
          <h3>Ancestors (in MRO)</h3>
          <ul class="class_list">
          <li><a href="#carl.learning.ParameterizedRegressor">ParameterizedRegressor</a></li>
          <li>carl.learning.parameterize._ParameterizedEstimator</li>
          <li>sklearn.base.BaseEstimator</li>
          <li>sklearn.base.RegressorMixin</li>
          <li>builtins.object</li>
          </ul>
          <h3>Static methods</h3>
            
  <div class="item">
    <div class="name def" id="carl.learning.ParameterizedRegressor.__init__">
    <p>def <span class="ident">__init__</span>(</p><p>self, base_estimator, params)</p>
    </div>
    

    
  
    <div class="desc"><p>Constructor.</p>
<h2>Parameters</h2>
<ul>
<li>
<p><code>base_estimator</code> [<code>BaseEstimator</code>]:
    The estimator to parameterize.</p>
</li>
<li>
<p><code>params</code> [list of Theano shared variables]:
    The parameters.</p>
</li>
</ul></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-carl.learning.ParameterizedRegressor.__init__', this);">Show source &equiv;</a></p>
  <div id="source-carl.learning.ParameterizedRegressor.__init__" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">base_estimator</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Constructor.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    * `base_estimator` [`BaseEstimator`]:</span>
<span class="sd">        The estimator to parameterize.</span>
<span class="sd">    * `params` [list of Theano shared variables]:</span>
<span class="sd">        The parameters.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">base_estimator</span> <span class="o">=</span> <span class="n">base_estimator</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">params</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="carl.learning.ParameterizedRegressor.fit">
    <p>def <span class="ident">fit</span>(</p><p>self, X, y)</p>
    </div>
    

    
  
    <div class="desc"><p>Fit estimator on parameterized data.</p>
<h2>Parameters</h2>
<ul>
<li>
<p><code>X</code> [array-like, shape=(n_samples, n_features+len(params))]:
    The samples, concatenated with the corresponding parameter values.</p>
</li>
<li>
<p><code>y</code> [array-like, shape=(n_samples,)]:
    The output values.</p>
</li>
</ul>
<h2>Returns</h2>
<ul>
<li><code>self</code> [object]:
    <code>self</code>.</li>
</ul></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-carl.learning.ParameterizedRegressor.fit', this);">Show source &equiv;</a></p>
  <div id="source-carl.learning.ParameterizedRegressor.fit" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Fit estimator on parameterized data.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    * `X` [array-like, shape=(n_samples, n_features+len(params))]:</span>
<span class="sd">        The samples, concatenated with the corresponding parameter values.</span>
<span class="sd">    * `y` [array-like, shape=(n_samples,)]:</span>
<span class="sd">        The output values.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    * `self` [object]:</span>
<span class="sd">        `self`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">stacker_</span> <span class="o">=</span> <span class="n">ParameterStacker</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
    <span class="c1"># XXX: this assumes that X is extended with parameters</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_features_</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">estimator_</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_estimator</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="carl.learning.ParameterizedRegressor.get_params">
    <p>def <span class="ident">get_params</span>(</p><p>self, deep=True)</p>
    </div>
    

    
  
    <div class="desc"><p>Get parameters for this estimator.</p>
<h2>Parameters</h2>
<p>deep: boolean, optional
    If True, will return the parameters for this estimator and
    contained subobjects that are estimators.</p>
<h2>Returns</h2>
<p>params : mapping of string to any
    Parameter names mapped to their values.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-carl.learning.ParameterizedRegressor.get_params', this);">Show source &equiv;</a></p>
  <div id="source-carl.learning.ParameterizedRegressor.get_params" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">get_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">deep</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get parameters for this estimator.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    deep: boolean, optional</span>
<span class="sd">        If True, will return the parameters for this estimator and</span>
<span class="sd">        contained subobjects that are estimators.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    params : mapping of string to any</span>
<span class="sd">        Parameter names mapped to their values.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">out</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_param_names</span><span class="p">():</span>
        <span class="c1"># We need deprecation warnings to always be on in order to</span>
        <span class="c1"># catch deprecated param values.</span>
        <span class="c1"># This is set in utils/__init__.py but it gets overwritten</span>
        <span class="c1"># when running under python3 somehow.</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;always&quot;</span><span class="p">,</span> <span class="ne">DeprecationWarning</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">(</span><span class="n">record</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">w</span><span class="p">:</span>
                <span class="n">value</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="ow">and</span> <span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">category</span> <span class="o">==</span> <span class="ne">DeprecationWarning</span><span class="p">:</span>
                <span class="c1"># if the parameter is deprecated, don&#39;t show it</span>
                <span class="k">continue</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">filters</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="c1"># XXX: should we rather test if instance of estimator?</span>
        <span class="k">if</span> <span class="n">deep</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="s1">&#39;get_params&#39;</span><span class="p">):</span>
            <span class="n">deep_items</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="n">out</span><span class="o">.</span><span class="n">update</span><span class="p">((</span><span class="n">key</span> <span class="o">+</span> <span class="s1">&#39;__&#39;</span> <span class="o">+</span> <span class="n">k</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">deep_items</span><span class="p">)</span>
        <span class="n">out</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
    <span class="k">return</span> <span class="n">out</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="carl.learning.ParameterizedRegressor.predict">
    <p>def <span class="ident">predict</span>(</p><p>self, X)</p>
    </div>
    

    
  
    <div class="desc"><p>Predict the targets for <code>X</code>.</p>
<p>Parameter values are automatically appended from the current state
of the parameters if those are not provided with <code>X</code>.</p>
<h2>Parameters</h2>
<ul>
<li><code>X</code> [array-like, shape=(n_samples, n_features) or
                   shape=(n_samples, n_features+len(params))]:
    The samples.</li>
</ul>
<h2>Returns</h2>
<ul>
<li><code>y</code> [array, shape=(n_samples,)]:
    The predicted output values.</li>
</ul></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-carl.learning.ParameterizedRegressor.predict', this);">Show source &equiv;</a></p>
  <div id="source-carl.learning.ParameterizedRegressor.predict" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Predict the targets for `X`.</span>
<span class="sd">    Parameter values are automatically appended from the current state</span>
<span class="sd">    of the parameters if those are not provided with `X`.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    * `X` [array-like, shape=(n_samples, n_features) or</span>
<span class="sd">                       shape=(n_samples, n_features+len(params))]:</span>
<span class="sd">        The samples.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    * `y` [array, shape=(n_samples,)]:</span>
<span class="sd">        The predicted output values.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator_</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_validate_X</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="carl.learning.ParameterizedRegressor.score">
    <p>def <span class="ident">score</span>(</p><p>self, X, y, sample_weight=None)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the regression
sum of squares ((y_true - y_pred) <strong> 2).sum() and v is the residual
sum of squares ((y_true - y_true.mean()) </strong> 2).sum().
Best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<h2>Parameters</h2>
<p>X : array-like, shape = (n_samples, n_features)
    Test samples.</p>
<p>y : array-like, shape = (n_samples) or (n_samples, n_outputs)
    True values for X.</p>
<p>sample_weight : array-like, shape = [n_samples], optional
    Sample weights.</p>
<h2>Returns</h2>
<p>score : float
    R^2 of self.predict(X) wrt. y.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-carl.learning.ParameterizedRegressor.score', this);">Show source &equiv;</a></p>
  <div id="source-carl.learning.ParameterizedRegressor.score" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the coefficient of determination R^2 of the prediction.</span>
<span class="sd">    The coefficient R^2 is defined as (1 - u/v), where u is the regression</span>
<span class="sd">    sum of squares ((y_true - y_pred) ** 2).sum() and v is the residual</span>
<span class="sd">    sum of squares ((y_true - y_true.mean()) ** 2).sum().</span>
<span class="sd">    Best possible score is 1.0 and it can be negative (because the</span>
<span class="sd">    model can be arbitrarily worse). A constant model that always</span>
<span class="sd">    predicts the expected value of y, disregarding the input features,</span>
<span class="sd">    would get a R^2 score of 0.0.</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : array-like, shape = (n_samples, n_features)</span>
<span class="sd">        Test samples.</span>
<span class="sd">    y : array-like, shape = (n_samples) or (n_samples, n_outputs)</span>
<span class="sd">        True values for X.</span>
<span class="sd">    sample_weight : array-like, shape = [n_samples], optional</span>
<span class="sd">        Sample weights.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    score : float</span>
<span class="sd">        R^2 of self.predict(X) wrt. y.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span>
    <span class="k">return</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
                    <span class="n">multioutput</span><span class="o">=</span><span class="s1">&#39;variance_weighted&#39;</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="carl.learning.ParameterizedRegressor.set_params">
    <p>def <span class="ident">set_params</span>(</p><p>self, **params)</p>
    </div>
    

    
  
    <div class="desc"><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The former have parameters of the form
<code>&lt;component&gt;__&lt;parameter&gt;</code> so that it's possible to update each
component of a nested object.</p>
<h2>Returns</h2>
<p>self</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-carl.learning.ParameterizedRegressor.set_params', this);">Show source &equiv;</a></p>
  <div id="source-carl.learning.ParameterizedRegressor.set_params" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">set_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Set the parameters of this estimator.</span>
<span class="sd">    The method works on simple estimators as well as on nested objects</span>
<span class="sd">    (such as pipelines). The former have parameters of the form</span>
<span class="sd">    ``&lt;component&gt;__&lt;parameter&gt;`` so that it&#39;s possible to update each</span>
<span class="sd">    component of a nested object.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    self</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">params</span><span class="p">:</span>
        <span class="c1"># Simple optimisation to gain speed (inspect is slow)</span>
        <span class="k">return</span> <span class="bp">self</span>
    <span class="n">valid_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_params</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">iteritems</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
        <span class="n">split</span> <span class="o">=</span> <span class="n">key</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;__&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">split</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># nested objects case</span>
            <span class="n">name</span><span class="p">,</span> <span class="n">sub_name</span> <span class="o">=</span> <span class="n">split</span>
            <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">valid_params</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Invalid parameter </span><span class="si">%s</span><span class="s1"> for estimator </span><span class="si">%s</span><span class="s1">. &#39;</span>
                                 <span class="s1">&#39;Check the list of available parameters &#39;</span>
                                 <span class="s1">&#39;with `estimator.get_params().keys()`.&#39;</span> <span class="o">%</span>
                                 <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="bp">self</span><span class="p">))</span>
            <span class="n">sub_object</span> <span class="o">=</span> <span class="n">valid_params</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
            <span class="n">sub_object</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="n">sub_name</span><span class="p">:</span> <span class="n">value</span><span class="p">})</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># simple objects case</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">valid_params</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Invalid parameter </span><span class="si">%s</span><span class="s1"> for estimator </span><span class="si">%s</span><span class="s1">. &#39;</span>
                                 <span class="s1">&#39;Check the list of available parameters &#39;</span>
                                 <span class="s1">&#39;with `estimator.get_params().keys()`.&#39;</span> <span class="o">%</span>
                                 <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__class__</span><span class="o">.</span><span class="n">__name__</span><span class="p">))</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span>
</pre></div>

  </div>
</div>

  </div>
  
      </div>
      </div>
  </section>

    </article>
  <div class="clear"> </div>
  <footer id="footer">
    <p>
      Documentation generated by
      <a href="https://github.com/BurntSushi/pdoc">pdoc 0.3.2</a>
    </p>

    <p>Design by <a href="http://nadh.in">Kailash Nadh</a></p>
  </footer>
</div>
</body>
</html>
